Baseline Version 1.0
====================

Version 1.0 is nearing completion (expected release in early October).  This version was designed to make the concepts in baseline simpler, easier to extend, more flexible, and easier to use.

Consideration went into making Baseline a better tool for API users -- people that might wish to develop outside of the `mead` driver and would prefer to use the API stand-alone.  Additionally, v1.0 simplifies the user experience for inference.  Here are some of the key changes that are in development for v1.0.

Additionally, the underlying changes have simplified mead considerably, making it easier to define custom model architectures purely in the JSON or YAML configuration files

- **hpctl**: The release of v1.0 of baseline includes this a new component. This is a program built on [**mead**](mead.md) but adds support for hyper-parameter searching to try and find optimal parameters using a template. It can be run across multiple GPUs.  Multiple search methods and backends are supported.

- API simplifications
  - **Vectorizers**: the cumbersome `featurizer` concept is gone and has been replaced by a much simpler [vectorizer](https://github.com/dpressel/baseline/blob/feature/v1/python/baseline/vectorizers.py)
    - vectorizers build initial dictionaries over tokens, and ultimately do the featurization, using a finalized vocabulary provided to them
    - These vectorizers can be serialized during training and reused for test
    - The vocabularies have serialization code, and are automatically serialized when using mead.
    - For tagging, dictionary-based vectorizers are supported which allows compositional features to be constructed from multiple columns of the CONLL file
  - **Embedding Representations**: The embedding concept has been updated to be more inline with recent NLP advances, particularly "contextual embeddings"
    - It is now possible to define sub-graphs for execution in each of the frameworks to represent an embedding
    - It was observed that the term embeddings is now used in literature to describe a token representation or multi-part sub-graph
      - typically this consists of a lookup table (what most frameworks call an `Embedding`) and optionally, a transformation of the lookup table outputs, for example, a BiLM used to produce a word representation
    - The previous `baseline.w2v` models still exist, and are adapted in a framework-specific way to generate the relevant sub-graph, facilitating a new feature for user-defined embeddings in each framework
      - This will make it easy to use custom embeddings that require LSTMs or Transformers or Convolutions in the sub-graph
  - **Model Simplifications**
    - Due to the *embeddings* improvements, the models have been greatly simplified.  The inputs to all default models have been simplified. The embeddings sub-graph concept allows models to delegate their sub-graphs for embeddings, and stores the sub-graph components in a dictionary
        - This also means that model methods like `make_input` are drastically simplified, as well as operations like TF exporting, which now can simply cycle the embedding keys.  It also means that models inherently can support multiple embeddings as long as they are time-aligned
        - Additionally, the models have been abstracted for an `embed` phase, which allows complex composition of multiple embeddings through extension of a single method
    - The vocabularies have been removed from the models.  This creates better Separation of Concerns (SoC) where an external object (the vectorizer) uses another external object (the vocabulary) to produce tensor representations for the model.  There are services that add support for a full bundle containing all 3 components, but this simplifies the models drastically
  - **Services**: The API support a user-friendly concept of a service (vs a component like the `ClassifierModel`) that has access to all 3 components required for inference (the vocabularies, the vectorizers and the models).  It delegates deserialization to each component and can load any backend framework model with a simple `XXXService.load(model)` API.  Inference is done using the transform method.  Full examples can be found for [classify](https://github.com/dpressel/baseline/blob/feature/v1/api-examples/classify-text.py), [tagging](https://github.com/dpressel/baseline/blob/feature/v1/api-examples/tag-text.py), [encoder-decoders](https://github.com/dpressel/baseline/blob/feature/v1/api-examples/ed-text.py) and [language modeling](https://github.com/dpressel/baseline/blob/feature/v1/api-examples/lm-text.py)
  - **Data/Reader Simplifications**: The readers have been simplified to use the `vectorizers` and the `DataFeed` and underlying support components have been greatly simplifed
    - The readers delegate counting to the vectorizers as well as featurization.  This is more DRY than in the previous releases.  This means that readers can handle much more complex features without special casing
    - The `Examples` and `DataFeed` objects are largely reused between tasks except when this is not possible
      - The batching operation on the examples is now completely generalized whih makes adding custom features simple
  - **Training Simplifications**: A design goal was that a user should easily be able to train a model without using `mead`.  [Here is how one could use the API to train](https://github.com/dpressel/baseline/blob/feature/v1/api-examples/tf-train-classifier-from-scratch.py)
  - **More Documentation**: There is more code documentation, as well as API examples that show how to use the **Baseline** API directly.  These are also used to self-verify that the API is as simple to use as possible.  There is forthcoming documentation on the way that `addons` work under the hood, as this has been a point of confusion for some users
- **mead**: mead has been simplified to have better underlying (and reusable) methods to reduce code.  It also has a new style of configuration file that is more cohesive, and more powerful than before.  Here is an [example of a tagger configuration using multiple embeddings and different vectorizers](https://github.com/dpressel/baseline/blob/feature/v1/python/mead/config/twpos.json) without adding any custom components.  These models tend to perform better than single embedding models but require no custom code.

- **xpctl**: The mongodb backend has changed to allow a simpler command syntax where a query can be made without having to know the `task` name
